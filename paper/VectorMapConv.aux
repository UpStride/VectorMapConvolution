\relax 
\citation{trabelsi+al-2018-complexconv}
\citation{aizenberg2018image}
\citation{takahashi2017remarks}
\citation{bayro2018geometric}
\citation{Gaudet2018}
\citation{parcollet2017deep}
\citation{parcollet2017quaternion}
\citation{parcollet2018quaternion-A}
\citation{parcollet2018quaternion-B}
\citation{parcollet2019quaternion}
\citation{kusamichi2004new}
\citation{isokawa2003quaternion}
\citation{parcollet2019quaternion}
\citation{pavllo2018quaternet}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\citation{tokuda2003trajectory}
\citation{matsui2004quaternion}
\citation{parcollet2019quaternion}
\citation{parcollet2018quaternion-A}
\citation{parcollet2018quaternion-A}
\citation{parcollet2018quaternion-A}
\citation{trabelsi+al-2018-complexconv}
\citation{Gaudet2018}
\@writefile{toc}{\contentsline {section}{\numberline {2}Motivation for Vector Map Convolutions}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Vector Map Components}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Illustration of the input features ($Q_{in}$) latent relations learning ability of a quaternion-valued layer (right) due to the quaternion weight sharing of the Hamilton product, compared to a standard real-valued layer (left) \cite  {parcollet2018quaternion-A}.}}{3}}
\newlabel{f:hamilton}{{1}{3}}
\citation{Gaudet2018}
\citation{trabelsi+al-2018-complexconv}
\citation{Gaudet2018}
\citation{glorot2010understanding}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Vector Map Convolution}{4}}
\newlabel{e:quatconv}{{1}{4}}
\newlabel{e:vmapconv}{{2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Vector Map Weight Initialization}{4}}
\newlabel{e:expected}{{3}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces An illustration of quaternion convolution.}}{5}}
\newlabel{f:quatconv}{{2}{5}}
\citation{he2015delving}
\citation{krizhevsky2009learning}
\citation{he2015deep}
\newlabel{e:vmap-glorot}{{4}{6}}
\newlabel{e:vmap-he}{{5}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Methods}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experimental Results}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Percent error for classification on CIFAR-10 and CIFAR-100. Params is the total number of parameters.}}{6}}
\newlabel{t:results}{{1}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Validation loss and accuracy plots corresponding to the experimental runs that produced Table\nobreakspace  {}1\hbox {}.}}{7}}
\newlabel{f:loss}{{3}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Histogram of $\textbf  {L}$ values after training of the ResNet18 vector map convolution network.}}{8}}
\newlabel{f:hist}{{4}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Randomly selected feature vector maps from the first convolution layer after training. Each row is a different image, where the first column are the original input images.}}{8}}
\newlabel{f:samples}{{5}{8}}
\bibstyle{plain}
\bibdata{vMap}
\bibcite{aizenberg2018image}{1}
\bibcite{bayro2018geometric}{2}
\bibcite{Gaudet2018}{3}
\bibcite{glorot2010understanding}{4}
\bibcite{he2015deep}{5}
\bibcite{he2015delving}{6}
\bibcite{isokawa2003quaternion}{7}
\bibcite{krizhevsky2009learning}{8}
\bibcite{kusamichi2004new}{9}
\bibcite{matsui2004quaternion}{10}
\bibcite{parcollet2017deep}{11}
\bibcite{parcollet2017quaternion}{12}
\bibcite{parcollet2019quaternion}{13}
\bibcite{parcollet2018quaternion-A}{14}
\bibcite{parcollet2018quaternion-B}{15}
\bibcite{pavllo2018quaternet}{16}
\bibcite{takahashi2017remarks}{17}
\bibcite{tokuda2003trajectory}{18}
\bibcite{trabelsi+al-2018-complexconv}{19}
